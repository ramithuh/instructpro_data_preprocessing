# instructpro_data_preprocessing

### Step 1: Downlaod the raw data

Download these files from the following links:
```bash
wget https://static.ramith.io/scientificLLM/data/ligand2smiles.json
wget https://static.ramith.io/scientificLLM/data/protein2ligand_id.json
wget https://static.ramith.io/scientificLLM/data/uniprot2seq.json
wget https://static.ramith.io/scientificLLM/data/uniprot2text.json
wget https://static.ramith.io/scientificLLM/data/uniref50.jsonl
```

### Step 2: Run the Analysis script to see the number of uniprot IDs that have all three: sequence, text, and associated ligands

Running this code will also save the uniprot IDs that have all three: sequence, text, and associated ligands to a file called `selected_uniprot_ids.txt`. This file will be later used for mmseqs2 to generate the clusters.

```bash
(py311) ramith@taurus:~/instructpro_data_preprocessing$ python 1.\ intersection_curation.py 
Protein to Ligand IDs: 12235657
UniProt to Sequence: 33617397
UniProt to Text: 35584366
Ligand, Sequence, and Text intersection: 7680607
Sequence and Text intersection: 33617397
Ligand and Text intersection: 7997705
All elements of seq appear in text
Elements in ligand but not in text: 4237952
Elements in ligand and text but not in seq: 317098
Uniref50 keys: 64363428
Biggest intersection after adding Uniref50: 273568
Regular Intersection: 7680607
Intersection with Uniref50: 273568
Total uniprot ids after adding Uniref50: 7718246
IDs have been saved to selected_uniprot_ids.txt
```

### Step 3: Generate a fasta file for the selected uniprot IDs and run mmseqs2 to generate clusters

Run the following python script to generate a fasta file.

```bash
(py311) ramith@taurus:~/instructpro_data_preprocessing$ python 2.\ make_fasta.py 
7680607 written from uniprot2seq.json
37639 written from uniref50.jsonl
0
```

Then run this to generate the clusters using mmseqs2: keep an eye out for the clusterRes_cluster.tsv which maps each protein sequence ID to a cluster ID. In our run, this resulted in 22,594 clusters [(mmseqs output)](https://static.ramith.io/scientificLLM/mmseqs2_attemp2.txt).

```bash
mmseqs easy-cluster output_sequences.fasta clusterRes tmp --min-seq-id 0.3 -c 0.8 --cov-mode 1
```

#### Split the clusters into train, validation, and test sets

This step uses the script `3. split_sets.py` to divide the ~22,594 protein clusters (obtained from MMseqs2 in Step 3) into training, validation, and test sets. The primary input for this script is the `clusterRes_cluster.tsv` file generated by MMseqs2.

The script performs the following key operations:
1.  **Calculates Cluster Sizes:** It reads the cluster content from `clusterRes_cluster.tsv` and determines the number of protein sequences within each cluster.

2.  **Stratified Sampling for Validation/Test:** To ensure a representative mix of cluster sizes in the valid and test sets, it employs a stratified sampling strategy. Clusters are binned by size (e.g., 1-500 sequences, 501-1000 sequences, etc.), and a predefined number of clusters are randomly sampled from each bin. For instance, 40 clusters are sampled from the 1-500 sequence count range, 20 from 501-1000, 10 from 1001-2500, and 2 from clusters with over 2500 sequences.

3.  **Assigns to Validation and Test:** This total pool of 72 sampled clusters is then divided equally (36 clusters each) to form the validation and test sets. This ensures each of these sets receives representation from the different cluster size bins (e.g., ~20 from the 1-500 bin, ~10 from the 501-1000 bin, etc., per set).

4.  **Assigns to Training:** All clusters not selected for either validation or test are assigned to the training set.

5.  **Outputs:** The script saves the lists of cluster IDs for each set into three separate files:
    * `train_clusters.txt`
    * `val_clusters.txt`
    * `test_clusters.txt`
    It also generates an HTML file, `cluster_histogram.html`, visualizing the distribution of sequence counts per cluster.

(script uses a fixed random seed (`42`) to ensure these splits are reproducible)

### Step 4: Designate Specific Ligands for Validation and Test Sets

This step uses the script `4. split_ligands.py` to define distinct sets of ligands that will be considered "unseen" during training. This is crucial for evaluating the model's ability to generalize to novel chemical compounds.

The script performs a refined selection process:

1.  **Initial Ligand Consideration:** It analyzes the distribution of all ligands associated with the 7.7 million selected proteins.
2.  **Integration with Protein Clusters:** It loads the previously defined validation and test protein cluster assignments (`val_clusters.txt`, `test_clusters.txt`) and identifies the actual ligands present within the proteins belonging to these clusters.
3.  **Refinement and Disambiguation:** An initial sampling of ligands is cross-referenced with the ligands found in the validation and test protein clusters. Any ligands that would ambiguously appear in both the refined validation and test ligand sets are removed to ensure strict separation.
4.  **Outputs:** The script saves the final, distinct lists of ligand IDs into two files:
    * `ligands_val.txt` (containing 9 unique ligands)
    * `ligands_test.txt` (containing 5 unique ligands)
